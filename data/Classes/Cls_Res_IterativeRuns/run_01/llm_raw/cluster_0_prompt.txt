
You are a very proactive class-resolution assistant.
You are given a set of candidate CLASSES that appear to belong, or may plausibly belong, to the same semantic cluster.
Your job is to produce a clear, *actionable* ordered list of schema edits for the given cluster.
Do NOT be passive. If the evidence supports structural change (merge / split / reassign / create), you MUST propose it.

Only return [] if there is extremely strong evidence that NO change is needed (rare).

The cluster grouping you are given is only *suggestive* and may be incorrect — your job is to resolve, correct, and produce a coherent schema from the evidence.

This is an iterative process — act now with well-justified structural corrections (include a short justification), rather than deferring small but meaningful fixes.
This step will be repeated in later iterations; reasonable but imperfect changes can be corrected later.
It is worse to miss a necessary change than to propose a well-justified change that might be slightly adjusted later.

Your CRUCIAL task is to refine the schema using this tentative grouping.

========================
SCHEMA STRUCTURE (CRITICAL)
========================

We are building a TWO-LAYER SCHEMA over entities:

Level 0: Class_Group        (connects related classes)
Level 1: Classes            (group entities)
Level 2: Entities

Structure:
Class_Group
  └── Class
        └── Entity

- Class_Group is the PRIMARY mechanism for connecting related classes.
- Classes that share a Class_Group are considered semantically related.
- This relationship propagates to their entities.

========================
IMPORTANT FIELD DISTINCTIONS
========================

- class_type_hint (existing field):
  A local, descriptive hint assigned to each class in isolation.
  It is often noisy, incomplete, and inconsistent across classes.
  Do NOT assume it is globally correct or reusable.

- class_label:
  Existing class_label values are PROVISIONAL names.
  You MAY revise them when entity evidence suggests a clearer or a better canonical label.

- Class_Group (NEW, CRUCIAL):
  A canonical upper-level grouping that emerges ONLY when multiple classes
  are considered together.
  It is used to connect related classes into a coherent schema.
  Class_Group is broader, more stable, and more reusable than class_type_hint.

- remarks (optional, internal):
  Free-text notes attached to a class, used to flag important issues that are
  outside the scope of structural changes (e.g., upstream entity resolution that you suspect is wrong, or entities that
  look identical but should not be changed here), DO NOT try to fix them via merge or reassign.
   Instead, attach a human-facing remark via modify_class (using the 'remark' field)
   so that a human can review it later.

Class_Group is NOT a synonym of class_type_hint.

========================
YOUR PRIMARY TASK
========================

Note: the provided cluster grouping is tentative and may be wrong — 
you must correct it as needed to produce a coherent Class_Group → Class → Entity schema.

For the given cluster of classes:

1) Assess whether any structural changes are REQUIRED:
   - merge duplicate or near-duplicate classes
   - reassign clearly mis-assigned entities
   - create a new class when necessary
   - split an overloaded class into more coherent subclasses when justified
   - modify class metadata when meaningfully incorrect

2) ALWAYS assess and assign an appropriate Class_Group:
   - If Class_Group is missing, null, or marked as TBD → you MUST assign it.
   - If Class_Group exists but is incorrect, misleading, or too narrow/broad → you MAY modify it.
   - If everything else is correct (which is not the case most of the time), assigning or confirming Class_Group ALONE is sufficient.

3) If you notice important issues that are OUTSIDE the scope of these functions
   (e.g., upstream entity resolution that you suspect is wrong, or entities that
   look identical but should not be changed here), DO NOT try to fix them via merge or reassign.
   Instead, attach a human-facing remark via modify_class (using the 'remark' field)
   so that a human can review it later.

========================
SOME CONSERVATISM RULES (They should not make you passive)
========================

- Always try to attempt structural proposals (merge/split/reassign/create) unless the cluster truly is already optimal.
- Do NOT perform cosmetic edits or unnecessary normalization.

You MAY perform multiple structural actions in one cluster
(e.g., merge + rename + reassign + split), when needed.

========================
MERGING & OVERLAP HEURISTICS
========================

- Entity overlap alone does not automatically require merging.
- Merge when evidence indicates the SAME underlying concepts
  (e.g., near-identical semantics, interchangeable usage, or redundant distinctions).
- Reassignment is appropriate when overlap reveals mis-typed or mis-scoped entities,
  even if classes should remain separate.

Quick heuristic:
- Same concept → merge.
- Different concept, same domain → keep separate classes with the SAME Class_Group.
- Different domain → different Class_Group.

Avoid vague Class_Group names (e.g., "Misc", "General", "Other").
Prefer domain-meaningful groupings that help connect related classes.

If a class should be collapsed or weakened but has no clear merge partner, DO NOT use merge_classes;
instead, reassign its entities to better classes and/or add a remark for human review.

IMPORTANT:
- You MUST NOT call merge_classes with only one class_id.
- merge_classes is ONLY for merging TWO OR MORE existing classes into ONE new class.
- If you only want to update or clarify a single class (for example, its label, description,
  type hint, class_group, or remarks), use modify_class instead.
- Do NOT use merge_classes to clean up or deduplicate entities inside one class.

========================
AVAILABLE FUNCTIONS
========================

Return ONLY a JSON ARRAY of ordered function calls.

Each object must have:
- "function": one of
  ["merge_classes", "create_class", "reassign_entities", "modify_class", "split_class"]
- "args": arguments as defined below.

ID HANDLING RULES
- You MUST NOT invent real class IDs.
- You MUST use ONLY class_ids that appear in the input CLASSES (candidate_id values),
  except when referring to newly merged/created/split classes.
- When you need to refer to a newly merged/created/split class in later steps,
  you MUST assign a provisional_id (any consistent string).
- Use the same provisional_id whenever referencing that new class again.
- After you merge classes into a new class, you should NOT continue to treat the original
  class_ids as separate entities; refer to the new merged class via its provisional_id.

Example (pattern, not required verbatim):

{
  "function": "merge_classes",
  "args": {
    "class_ids": ["ClsC_da991b68", "ClsC_e32f4a47"],
    "provisional_id": "MERGE(ClsC_da991b68|ClsC_e32f4a47)",
    "new_name": "...",
    "new_description": "...",
    "new_class_type_hint": "Standard",
    "justification": "One-line reason citing entity overlap and semantic equivalence.",
    "remark": null,
    "confidence": 0.95
  }
}

Later:

{
  "function": "reassign_entities",
  "args": {
    "entity_ids": ["En_xxx"],
    "from_class_id": "ClsC_e32f4a47",
    "to_class_id": "MERGE(ClsC_da991b68|ClsC_e32f4a47)",
    "justification": "Why this entity fits better in the merged class.",
    "remark": null,
    "confidence": 0.9
  }
}

We will internally map provisional_id → real class id.

------------------------
Function definitions
------------------------

JUSTIFICATION REQUIREMENT
- Every function call MUST include:
    "justification": "<one-line reason>"
  explaining why the action is necessary.
- This justification should cite concrete evidence (entity overlap, conflicting descriptions,
  mis-scoped members, missing Class_Group, overloaded classes, etc.).
- You MAY also include "confidence": <0.0–1.0> to indicate your belief in the action.
- You MAY include "remark" to provide a short human-facing note.

1) merge_classes
args = {
  "class_ids": [<existing_class_ids>],   # MUST contain at least 2 valid ids
  "provisional_id": <string or null>,    # how you will refer to the new class later
  "new_name": <string or null>,
  "new_description": <string or null>,
  "new_class_type_hint": <string or null>,
  "justification": <string>,
  "remark": <string or null>,            # optional: attach a human-facing remark/flag
  "confidence": <number between 0 and 1, optional>
}

2) create_class
args = {
  "name": <string>,
  "description": <string or null>,
  "class_type_hint": <string or null>,
  "member_ids": [<entity_ids>],          # optional, must be from provided entities
  "provisional_id": <string or null>,    # how you will refer to this new class later
  "justification": <string>,
  "remark": <string or null>,            # optional: attach a human-facing remark/flag
  "confidence": <number between 0 and 1, optional>
}

3) reassign_entities
args = {
  "entity_ids": [<entity_ids>],
  "from_class_id": <existing_class_id or provisional_id or null>,
  "to_class_id": <existing_class_id or provisional_id>,
  "justification": <string>,
  "remark": <string or null>,            # optional: attach a human-facing remark/flag
  "confidence": <number between 0 and 1, optional>
}

4) modify_class
args = {
  "class_id": <existing_class_id or provisional_id>,
  "new_name": <string or null>,
  "new_description": <string or null>,
  "new_class_type_hint": <string or null>,
  "new_class_group": <string or null>,
  "remark": <string or null>,            # optional: attach a human-facing remark/flag
  "justification": <string>,
  "confidence": <number between 0 and 1, optional>
}

- Use modify_class with 'remark' (and no structural change) when you want to flag
  issues that are outside the scope of this step (e.g., suspected entity-level duplicates).

5) split_class
args = {
  "source_class_id": <existing_class_id or provisional_id>,
  "splits": [
    {
      "name": <string or null>,
      "description": <string or null>,
      "class_type_hint": <string or null>,
      "member_ids": [<entity_ids>],      # must be from source_class member_ids
      "provisional_id": <string or null> # how you will refer to this new split class
    },
    ...
  ],
  "justification": <string>,
  "remark": <string or null>,            # optional: attach a human-facing remark/flag
  "confidence": <number between 0 and 1, optional>
}

Semantics of split_class:
- Use split_class when a single class is overloaded and should be divided into
  narrower, more coherent classes.
- Entities listed in splits[*].member_ids MUST come from the source_class's member_ids.
- The specified entities are REMOVED from the source_class and grouped into new classes.
- Any members not mentioned in any split remain in the source_class.

NOTE:
- Class_Group is normally set or updated via modify_class.
- Assigning or confirming Class_Group is also REQUIRED for every cluster unless it is already clearly correct.

========================
VALIDATION RULES
========================

- Use ONLY provided entity_ids and class_ids (candidate_id values) for existing classes.
- For new classes, use provisional_id handles and be consistent.
- Order matters: later steps may depend on earlier ones.
- merge_classes with fewer than 2 valid class_ids will be ignored.

========================
STRATEGY GUIDANCE
========================

- Prefer assigning/adjusting Class_Group over heavy structural changes when both are valid.
- Merge classes ONLY when they are genuinely redundant (same concept).
- Use split_class when a class clearly bundles multiple distinct concepts that should be separated.
- If classes are related but distinct:
  → keep them separate and connect them via the SAME Class_Group.
- Think in terms of schema connectivity and meaningful structure, not cosmetic cleanup.
- If in doubt about structural change but you see a potential issue, use modify_class with a 'remark'
  rather than forcing an uncertain structural edit.

========================
INPUT CLASSES
========================

Each class includes:
- candidate_id
- class_label
- class_description
- class_type_hint
- class_group (may be null or "TBD")
- confidence
- evidence_excerpt
- member_ids
- members (entity id, name, description, type)
- remarks (optional list of prior remarks)

[
  {
    "candidate_id": "ClsC_42a3ff76",
    "class_label": "AI Ethics Concepts",
    "class_description": "Normative concepts used to evaluate the ethical acceptability of AI systems and their impacts, including bias as a harm mechanism and fairness/equity as desired conditions.",
    "class_type_hint": "Ethical Principle",
    "class_group": "TBD",
    "confidence": 0.9,
    "evidence_excerpt": "AI bias as an ethical concern and damage mechanism; ensuring fairness and equity in decision-making processes.",
    "member_ids": [
      "Can_5f153ade",
      "En_6c6c854a",
      "En_d9389e81"
    ],
    "members": [
      {
        "id": "Can_5f153ade",
        "entity_name": "bias in AI systems",
        "entity_description": "Systematic, unfair, or discriminatory tendencies in AI systems arising from biased or incomplete data, design choices, or deployment contexts, which can disadvantage certain groups or lead to inequitable outcomes.",
        "entity_type_hint": "Concept"
      },
      {
        "id": "En_6c6c854a",
        "entity_name": "fairness",
        "entity_description": "The quality of decisions or processes being impartial and just across affected groups.",
        "entity_type_hint": "Condition"
      },
      {
        "id": "En_d9389e81",
        "entity_name": "equity",
        "entity_description": "Condition where outcomes and opportunities are adjusted to account for structural disadvantages.",
        "entity_type_hint": "Condition"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_01330fd0",
    "class_label": "AI Surveillance Technologies",
    "class_description": "Technological systems that use artificial intelligence to monitor or track individuals or groups, such as facial recognition used for surveillance purposes.",
    "class_type_hint": "Technology Category",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "facial recognition technology can be used for surveillance purposes",
    "member_ids": [
      "En_d3f49663",
      "En_c9fa581d"
    ],
    "members": [
      {
        "id": "En_d3f49663",
        "entity_name": "facial recognition technology",
        "entity_description": "AI-based technology that identifies or verifies individuals using their facial features.",
        "entity_type_hint": "Component"
      },
      {
        "id": "En_c9fa581d",
        "entity_name": "surveillance purposes",
        "entity_description": "Use of technologies to monitor or track individuals or groups.",
        "entity_type_hint": "OperatingCondition"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_2a41b464",
    "class_label": "AI Institutional Actors",
    "class_description": "Organizations that may deploy or develop AI and surveillance technologies, including public authorities and private-sector corporations.",
    "class_type_hint": "Actor Category",
    "class_group": "TBD",
    "confidence": 0.9,
    "evidence_excerpt": "abuse of power by governments or corporations",
    "member_ids": [
      "En_960e1bbe",
      "En_ad2a7d77"
    ],
    "members": [
      {
        "id": "En_960e1bbe",
        "entity_name": "governments",
        "entity_description": "Public authorities that may deploy AI and surveillance technologies.",
        "entity_type_hint": "Organization"
      },
      {
        "id": "En_ad2a7d77",
        "entity_name": "corporations",
        "entity_description": "Private-sector organizations that may develop or use AI technologies, including facial recognition.",
        "entity_type_hint": "Organization"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_dda92042",
    "class_label": "Algorithmic Bias",
    "class_description": "Concepts describing how AI or algorithmic systems produce unfair or discriminatory results, including the biased systems themselves and their outcomes.",
    "class_type_hint": "Failure Mechanism",
    "class_group": "TBD",
    "confidence": 0.93,
    "evidence_excerpt": "Biased algorithms in AI systems can lead to discriminatory outcomes.",
    "member_ids": [
      "En_93b27f7a",
      "En_981f0165"
    ],
    "members": [
      {
        "id": "En_93b27f7a",
        "entity_name": "discriminatory outcomes",
        "entity_description": "Unfair or unequal results produced by AI systems against certain individuals or groups.",
        "entity_type_hint": "FailureEvent"
      },
      {
        "id": "En_981f0165",
        "entity_name": "biased algorithms",
        "entity_description": "Algorithms whose design or training data leads to systematically unfair or discriminatory outcomes.",
        "entity_type_hint": "DamageMechanism"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_446932f3",
    "class_label": "Discriminatory Treatment",
    "class_description": "Events or states involving unjust or prejudicial treatment of individuals or groups, including general discrimination and its realized outcomes.",
    "class_type_hint": "Failure Event",
    "class_group": "TBD",
    "confidence": 0.88,
    "evidence_excerpt": "Unfair or unequal results and unjust or prejudicial treatment of individuals or groups.",
    "member_ids": [
      "En_93b27f7a",
      "En_e24497ac"
    ],
    "members": [
      {
        "id": "En_93b27f7a",
        "entity_name": "discriminatory outcomes",
        "entity_description": "Unfair or unequal results produced by AI systems against certain individuals or groups.",
        "entity_type_hint": "FailureEvent"
      },
      {
        "id": "En_e24497ac",
        "entity_name": "discrimination",
        "entity_description": "Unjust or prejudicial treatment of individuals or groups based on protected characteristics.",
        "entity_type_hint": "FailureEvent"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_f28cb1bb",
    "class_label": "Protected Characteristics",
    "class_description": "Demographic attributes that are legally or ethically protected and commonly referenced in discussions of discrimination and fairness.",
    "class_type_hint": "Attribute",
    "class_group": "TBD",
    "confidence": 0.96,
    "evidence_excerpt": "Race and gender as protected demographic characteristics in discrimination contexts.",
    "member_ids": [
      "En_aefbfcea",
      "En_341fc99b"
    ],
    "members": [
      {
        "id": "En_aefbfcea",
        "entity_name": "race",
        "entity_description": "A protected demographic characteristic often associated with discriminatory treatment in decisions.",
        "entity_type_hint": "Attribute"
      },
      {
        "id": "En_341fc99b",
        "entity_name": "gender",
        "entity_description": "A protected demographic characteristic frequently implicated in biased or unequal treatment.",
        "entity_type_hint": "Attribute"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_7884cff9",
    "class_label": "AI Training Data",
    "class_description": "Datasets used to train AI systems, including general training data and problematic subsets such as biased or incomplete data that can cause discriminatory or unreliable behavior.",
    "class_type_hint": "Data Asset",
    "class_group": "TBD",
    "confidence": 0.96,
    "evidence_excerpt": "AI systems are only as good as the data they are trained on, and if this data is biased or incomplete...",
    "member_ids": [
      "En_233d0bd9",
      "En_9bc351d3",
      "En_34e84e77"
    ],
    "members": [
      {
        "id": "En_233d0bd9",
        "entity_name": "training data",
        "entity_description": "Data used to train AI systems, determining their performance and behavior.",
        "entity_type_hint": "DataAsset"
      },
      {
        "id": "En_9bc351d3",
        "entity_name": "biased data",
        "entity_description": "Training data containing systematic prejudice or skew, leading to unfair AI behavior.",
        "entity_type_hint": "DataAsset"
      },
      {
        "id": "En_34e84e77",
        "entity_name": "incomplete data",
        "entity_description": "Training data that lacks sufficient or representative information about the target population or domain.",
        "entity_type_hint": "DataAsset"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_7d013e67",
    "class_label": "Problematic Training Data",
    "class_description": "Subtypes of AI training data characterized by quality or representativeness issues, such as systematic bias or missing coverage, that can lead to discriminatory outcomes.",
    "class_type_hint": "Data Quality Issue",
    "class_group": "TBD",
    "confidence": 0.93,
    "evidence_excerpt": "if this data is biased or incomplete, it can lead to discriminatory outcomes",
    "member_ids": [
      "En_9bc351d3",
      "En_34e84e77"
    ],
    "members": [
      {
        "id": "En_9bc351d3",
        "entity_name": "biased data",
        "entity_description": "Training data containing systematic prejudice or skew, leading to unfair AI behavior.",
        "entity_type_hint": "DataAsset"
      },
      {
        "id": "En_34e84e77",
        "entity_name": "incomplete data",
        "entity_description": "Training data that lacks sufficient or representative information about the target population or domain.",
        "entity_type_hint": "DataAsset"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_f3159e95",
    "class_label": "AI Socioeconomic Impacts",
    "class_description": "Societal and economic outcomes influenced by AI adoption, including positive effects like increased productivity and negative effects such as job displacement and inequality.",
    "class_type_hint": "Societal Impact",
    "class_group": "TBD",
    "confidence": 0.93,
    "evidence_excerpt": "AI technologies... bring benefits, such as improved efficiency and productivity, [and] raise concerns about job displacement, inequality",
    "member_ids": [
      "En_8b90e664",
      "En_ab9dfae7",
      "En_a9f68a35"
    ],
    "members": [
      {
        "id": "En_8b90e664",
        "entity_name": "productivity",
        "entity_description": "Amount of useful output or work achieved, which AI can help to increase.",
        "entity_type_hint": "Benefit"
      },
      {
        "id": "En_ab9dfae7",
        "entity_name": "job displacement",
        "entity_description": "Loss or shifting of employment roles caused by adoption of AI technologies.",
        "entity_type_hint": "Phenomenon"
      },
      {
        "id": "En_a9f68a35",
        "entity_name": "inequality",
        "entity_description": "Uneven distribution of opportunities, income, or power that may be exacerbated by AI.",
        "entity_type_hint": "Phenomenon"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_c3af27b0",
    "class_label": "AI Societal Impacts",
    "class_description": "Concepts describing how AI technologies affect society, including benefits like efficiency gains and risks such as concentrated power among dominant actors.",
    "class_type_hint": "Societal Impact",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "AI technologies have the potential to bring about significant benefits... they also raise concerns about... concentration of power",
    "member_ids": [
      "En_985f94b9",
      "En_26270cf5"
    ],
    "members": [
      {
        "id": "En_985f94b9",
        "entity_name": "improved efficiency",
        "entity_description": "Increase in the effectiveness and speed of processes enabled by AI technologies.",
        "entity_type_hint": "Benefit"
      },
      {
        "id": "En_26270cf5",
        "entity_name": "concentration of power",
        "entity_description": "Accumulation of decision-making and economic influence in a small group due to AI.",
        "entity_type_hint": "Phenomenon"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_5df9057e",
    "class_label": "AI Power Holders",
    "class_description": "Entities that may hold or embody concentrated economic and decision-making power in the AI ecosystem, such as dominant corporations.",
    "class_type_hint": "Actor",
    "class_group": "TBD",
    "confidence": 0.8,
    "evidence_excerpt": "concentration of power in the hands of a few corporations",
    "member_ids": [
      "En_26270cf5",
      "En_5420c77a"
    ],
    "members": [
      {
        "id": "En_26270cf5",
        "entity_name": "concentration of power",
        "entity_description": "Accumulation of decision-making and economic influence in a small group due to AI.",
        "entity_type_hint": "Phenomenon"
      },
      {
        "id": "En_5420c77a",
        "entity_name": "corporations",
        "entity_description": "Large business organizations that may control powerful AI technologies and resources.",
        "entity_type_hint": "Organization"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_7aefe6ac",
    "class_label": "Privacy Rights",
    "class_description": "Ethical and legal concepts concerned with individuals’ control over personal and sensitive information, especially in technological and AI contexts.",
    "class_type_hint": "Ethical Principle",
    "class_group": "TBD",
    "confidence": 0.93,
    "evidence_excerpt": "Ethical-legal right and concern over control and protection of personal information.",
    "member_ids": [
      "Can_6d842f51",
      "Can_38441217"
    ],
    "members": [
      {
        "id": "Can_6d842f51",
        "entity_name": "right to privacy",
        "entity_description": "The legal and moral rights of individuals to keep their personal information and activities private and to control access to their personal data.",
        "entity_type_hint": "EthicalPrinciple"
      },
      {
        "id": "Can_38441217",
        "entity_name": "privacy",
        "entity_description": "An ethical concern and conceptual issue regarding the protection of personal and sensitive information in the context of AI technologies.",
        "entity_type_hint": "Concept"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_3855a314",
    "class_label": "AI System Responsibility Concepts",
    "class_description": "Concepts involved in discussions of responsibility and accountability for AI behavior, including the AI system as a potential actor and the errors or harms it produces.",
    "class_type_hint": "Responsibility Concept",
    "class_group": "TBD",
    "confidence": 0.78,
    "evidence_excerpt": "Who is responsible when an AI system makes a mistake or causes harm?",
    "member_ids": [
      "Can_0211509c",
      "En_225b9bfb"
    ],
    "members": [
      {
        "id": "Can_0211509c",
        "entity_name": "AI system error or harm",
        "entity_description": "An erroneous action, decision, or resulting negative impact produced by an AI system.",
        "entity_type_hint": "FailureEvent"
      },
      {
        "id": "En_225b9bfb",
        "entity_name": "AI system itself",
        "entity_description": "The AI system considered as a potential bearer of responsibility.",
        "entity_type_hint": "Actor"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_891fa7d2",
    "class_label": "AI Ethics Discourse",
    "class_description": "Conceptual and textual treatments of ethical dilemmas arising in the development and deployment of artificial intelligence systems, including both the abstract moral issues and documents explicitly discussing them.",
    "class_type_hint": "Thematic Topic",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "Both refer to ethical dilemmas specific to AI development; one as a recurring ethical concept, the other as a document title on the same topic.",
    "member_ids": [
      "Can_22528e3f",
      "En_69d1922a"
    ],
    "members": [
      {
        "id": "Can_22528e3f",
        "entity_name": "ethical dilemmas in AI development",
        "entity_description": "Complex moral conflicts and issues that arise in the design, development, and deployment of artificial intelligence technologies, including concerns such as privacy, bias, accountability, transparency, and societal impact.",
        "entity_type_hint": "EthicalConcept"
      },
      {
        "id": "En_69d1922a",
        "entity_name": "Ethical Dilemmas in AI Development",
        "entity_description": "Textual discussion focused on ethical dilemmas arising from the development of artificial intelligence systems.",
        "entity_type_hint": "Document"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_890d54c4",
    "class_label": "AI Decision Explainability",
    "class_description": "Concepts related to AI systems’ decisions and the human-understandable explanations of how those decisions are produced, supporting transparency and accountability.",
    "class_type_hint": "AI Governance Concept",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "Human-understandable explanations of how AI systems make decisions and execute internal processes; AI system decisions as outputs or choices.",
    "member_ids": [
      "Can_c1751366",
      "En_560ba8c4"
    ],
    "members": [
      {
        "id": "Can_c1751366",
        "entity_name": "explanations for AI decisions and processes",
        "entity_description": "Human-understandable justifications and descriptions of how AI systems make decisions and execute internal processes, used to improve transparency, trust, and accountability.",
        "entity_type_hint": "MitigationAction"
      },
      {
        "id": "En_560ba8c4",
        "entity_name": "AI system decisions",
        "entity_description": "Outputs or choices produced by AI systems in response to inputs or situations.",
        "entity_type_hint": "Event"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_75828e8c",
    "class_label": "AI System Transparency",
    "class_description": "Concepts describing the transparency of AI systems and its role in shaping stakeholder perceptions, including both the presence and absence of transparency and its impact on trust, acceptance, and adoption.",
    "class_type_hint": "Socio-Technical Concept",
    "class_group": "TBD",
    "confidence": 0.93,
    "evidence_excerpt": "Degree to which AI systems’ processes are understandable vs. condition where decision-making is not visible.",
    "member_ids": [
      "Can_36886a98",
      "En_e13e3f0a"
    ],
    "members": [
      {
        "id": "Can_36886a98",
        "entity_name": "transparency in AI systems",
        "entity_description": "The degree to which AI systems’ processes and decision logic are open, understandable, and explainable to stakeholders, used both as a general property and as a design practice to enhance trust and accountability.",
        "entity_type_hint": "Concept"
      },
      {
        "id": "En_e13e3f0a",
        "entity_name": "lack of transparency",
        "entity_description": "Condition where AI systems’ decision-making processes are not visible or understandable to stakeholders.",
        "entity_type_hint": "Condition"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_2cd5b2d8",
    "class_label": "Trust in AI Systems",
    "class_description": "Attitudinal states of stakeholders toward AI systems, covering both positive trust and negative distrust as key factors in system acceptance.",
    "class_type_hint": "Psychological State",
    "class_group": "TBD",
    "confidence": 0.9,
    "evidence_excerpt": "Distrust as skepticism or lack of confidence vs. trust as confidence AI will behave reliably.",
    "member_ids": [
      "En_4658a580",
      "En_7a0d326e"
    ],
    "members": [
      {
        "id": "En_4658a580",
        "entity_name": "distrust in AI systems",
        "entity_description": "Skepticism or lack of confidence among users or stakeholders toward AI systems.",
        "entity_type_hint": "Symptom"
      },
      {
        "id": "En_7a0d326e",
        "entity_name": "trust in AI systems",
        "entity_description": "Confidence that AI systems will behave reliably and as intended.",
        "entity_type_hint": "Concept"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_0682ec86",
    "class_label": "AI System Uptake",
    "class_description": "Concepts related to whether and how AI systems come into regular use, including willingness to use them and the process of integrating them into practice.",
    "class_type_hint": "Socio-Technical Process",
    "class_group": "TBD",
    "confidence": 0.88,
    "evidence_excerpt": "Acceptance as willingness to use vs. adoption as integration into regular use.",
    "member_ids": [
      "En_f182ba96",
      "En_682f30cf"
    ],
    "members": [
      {
        "id": "En_f182ba96",
        "entity_name": "acceptance of AI systems",
        "entity_description": "The willingness of individuals or organizations to use or embrace AI systems.",
        "entity_type_hint": "Condition"
      },
      {
        "id": "En_682f30cf",
        "entity_name": "adoption of AI systems",
        "entity_description": "The process by which AI systems are integrated into regular use by users or institutions.",
        "entity_type_hint": "Process"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_da406864",
    "class_label": "AI Ethics Norms",
    "class_description": "Normative concepts that govern how AI should be developed and deployed, including explicit rules, high-level moral principles, and calls to act in a responsible and ethical manner.",
    "class_type_hint": "Governance Concept",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "Normative guidance for responsible, ethical AI development and deployment, including rules and principles.",
    "member_ids": [
      "Can_d2ad650f",
      "En_8bdcb18c",
      "En_3fa5be25"
    ],
    "members": [
      {
        "id": "Can_d2ad650f",
        "entity_name": "ethical guidelines",
        "entity_description": "Explicit normative rules and principles intended to govern the responsible development and deployment of AI technologies.",
        "entity_type_hint": "MitigationAction"
      },
      {
        "id": "En_8bdcb18c",
        "entity_name": "ethical principles",
        "entity_description": "Moral guidelines intended to shape how AI technologies are developed and used.",
        "entity_type_hint": "Concept"
      },
      {
        "id": "En_3fa5be25",
        "entity_name": "responsible and ethical manner",
        "entity_description": "A mode of developing and deploying AI that adheres to ethical principles and responsibility.",
        "entity_type_hint": "OperatingCondition"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_faff2019",
    "class_label": "AI Accountability",
    "class_description": "Concepts concerned with assigning and structuring responsibility for AI system decisions, behaviors, and outcomes across involved actors.",
    "class_type_hint": "Governance Concept",
    "class_group": "TBD",
    "confidence": 0.93,
    "evidence_excerpt": "responsibility for AI decisions and impacts; establish clear lines of accountability",
    "member_ids": [
      "Can_677b3d47",
      "En_e76bc9ae"
    ],
    "members": [
      {
        "id": "Can_677b3d47",
        "entity_name": "accountability",
        "entity_description": "The assignment of responsibility for AI system decisions, behaviors, and outcomes in their development and deployment.",
        "entity_type_hint": "Concept"
      },
      {
        "id": "En_e76bc9ae",
        "entity_name": "lines of accountability",
        "entity_description": "Specified allocations of responsibility among actors when AI systems cause outcomes.",
        "entity_type_hint": "Concept"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_81c254c4",
    "class_label": "AI Social Stakeholders",
    "class_description": "Collective human groups and social structures (society, communities, and their well-being) that are impacted by AI technologies and considered in ethical AI discussions.",
    "class_type_hint": "Stakeholder Group",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "Groups of people and society as a whole affected by AI and whose well-being is prioritized.",
    "member_ids": [
      "Can_35f75da6",
      "En_e326b183",
      "En_c7cdbd8a"
    ],
    "members": [
      {
        "id": "Can_35f75da6",
        "entity_name": "society",
        "entity_description": "The broader social collective or society as a whole that is impacted by AI systems and their deployment.",
        "entity_type_hint": "Environment"
      },
      {
        "id": "En_e326b183",
        "entity_name": "well-being of individuals and communities",
        "entity_description": "Overall health, welfare, and quality of life for people and social groups affected by AI.",
        "entity_type_hint": "Concept"
      },
      {
        "id": "En_c7cdbd8a",
        "entity_name": "communities",
        "entity_description": "Groups of people or societies collectively impacted by AI technologies.",
        "entity_type_hint": "Actor"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_edea542b",
    "class_label": "AI System Stakeholders",
    "class_description": "Human parties directly involved with or impacted by AI systems, including those who design them, operate them, or are affected by their decisions.",
    "class_type_hint": "Actor Category",
    "class_group": "TBD",
    "confidence": 0.93,
    "evidence_excerpt": "Persons whose lives may be affected; people or organizations that design AI; end-users who deploy or interact with AI.",
    "member_ids": [
      "Can_cf564007",
      "En_38023a87",
      "En_a3e5ecec"
    ],
    "members": [
      {
        "id": "Can_cf564007",
        "entity_name": "individuals",
        "entity_description": "Persons whose lives, rights, or opportunities may be affected by AI system decisions.",
        "entity_type_hint": "Actor"
      },
      {
        "id": "En_38023a87",
        "entity_name": "developers",
        "entity_description": "People or organizations that design, build, or train AI systems.",
        "entity_type_hint": "Actor"
      },
      {
        "id": "En_a3e5ecec",
        "entity_name": "users",
        "entity_description": "End-users or operators who deploy or interact with AI systems.",
        "entity_type_hint": "Actor"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_e1ee2a50",
    "class_label": "AI Societal Implications",
    "class_description": "High-level concepts concerning how artificial intelligence affects society and the beneficial opportunities it offers, including both its broad societal impact and its potential to be harnessed for social good.",
    "class_type_hint": "Socio-Technical Concept",
    "class_group": "TBD",
    "confidence": 0.78,
    "evidence_excerpt": "broader societal implications of AI technologies and harnessing the potential of AI for the benefit of all",
    "member_ids": [
      "Can_6e521b24",
      "En_d21dd85b"
    ],
    "members": [
      {
        "id": "Can_6e521b24",
        "entity_name": "societal impact of AI technologies",
        "entity_description": "The broad social, economic, cultural, and ethical consequences that artificial intelligence and its applications may have on society, communities, and social structures.",
        "entity_type_hint": "Phenomenon"
      },
      {
        "id": "En_d21dd85b",
        "entity_name": "potential of AI",
        "entity_description": "The beneficial capabilities and opportunities offered by artificial intelligence systems.",
        "entity_type_hint": "Concept"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_48eeb186",
    "class_label": "Artificial Intelligence Technologies",
    "class_description": "Concepts and systems related to artificial intelligence as a technological field, including the core technology and its concrete technological applications in society.",
    "class_type_hint": "Technology Domain",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "AI technologies as concrete systems and Artificial Intelligence as the core technological field.",
    "member_ids": [
      "Can_c45dd68a",
      "En_b2346235"
    ],
    "members": [
      {
        "id": "Can_c45dd68a",
        "entity_name": "AI technologies",
        "entity_description": "Technological systems, tools, and applications that use artificial intelligence methods and algorithms and are deployed across industries and daily life.",
        "entity_type_hint": "Technology"
      },
      {
        "id": "En_b2346235",
        "entity_name": "Artificial Intelligence",
        "entity_description": "A rapidly advancing technological field that is revolutionizing industries and daily life.",
        "entity_type_hint": "Technology"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_885caf33",
    "class_label": "AI Technology Lifecycle Processes",
    "class_description": "Process stages in the lifecycle of AI technologies, covering their research, design, development, and subsequent deployment into real-world environments.",
    "class_type_hint": "Process",
    "class_group": "TBD",
    "confidence": 0.9,
    "evidence_excerpt": "Development and deployment described as distinct lifecycle stages for AI technologies.",
    "member_ids": [
      "Can_048be6b8",
      "Can_f7dea021"
    ],
    "members": [
      {
        "id": "Can_048be6b8",
        "entity_name": "development of AI technologies",
        "entity_description": "The processes and activities involved in researching, designing, building, training, and improving artificial intelligence technologies and applications, including their preparation for deployment.",
        "entity_type_hint": "Process"
      },
      {
        "id": "Can_f7dea021",
        "entity_name": "deployment of AI technologies",
        "entity_description": "The process of releasing, integrating, and using AI technologies in real-world applications and environments.",
        "entity_type_hint": "Process"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_bd45abda",
    "class_label": "AI Systems",
    "class_description": "Artificial intelligence systems that collect and analyze data, support or make decisions, and may operate autonomously using complex, often opaque algorithms.",
    "class_type_hint": "Sociotechnical System",
    "class_group": "TBD",
    "confidence": 0.9,
    "evidence_excerpt": "AI systems that collect and analyze data, make or support decisions, and may operate autonomously",
    "member_ids": [
      "Can_c983eba4"
    ],
    "members": [
      {
        "id": "Can_c983eba4",
        "entity_name": "AI systems",
        "entity_description": "Artificial intelligence systems that collect and analyze data, make or support decisions, and may operate autonomously using complex, often opaque algorithms.",
        "entity_type_hint": "FunctionalUnit"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_43d1d6d8",
    "class_label": "AI Regulations",
    "class_description": "Formal legal and rule-based frameworks that govern the development, deployment, and use of AI technologies, including compliance obligations and enforcement mechanisms.",
    "class_type_hint": "Governance Mechanism",
    "class_group": "TBD",
    "confidence": 0.9,
    "evidence_excerpt": "Formal rules and legal frameworks designed to govern and control how AI technologies are developed, deployed, and used.",
    "member_ids": [
      "Can_1d58c2bc"
    ],
    "members": [
      {
        "id": "Can_1d58c2bc",
        "entity_name": "regulations",
        "entity_description": "Formal rules and legal frameworks designed to govern and control how AI technologies are developed, deployed, and used.",
        "entity_type_hint": "MitigationAction"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_8793c241",
    "class_label": "Massive Data Assets",
    "class_description": "Large-scale datasets collected and analyzed by AI systems, typically involving extensive personal or behavioral information and raising privacy and governance concerns.",
    "class_type_hint": "Data Asset",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "Large-scale datasets collected and analyzed by AI systems, raising privacy concerns.",
    "member_ids": [
      "En_ac8428bd"
    ],
    "members": [
      {
        "id": "En_ac8428bd",
        "entity_name": "massive amounts of data",
        "entity_description": "Large-scale datasets collected and analyzed by AI systems.",
        "entity_type_hint": "DataAsset"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_c5c16241",
    "class_label": "Abuse of Power",
    "class_description": "Instances where authority or institutional power is misused, including when AI or surveillance technologies enable overreach or rights violations.",
    "class_type_hint": "Societal Risk",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "Facial recognition technology used for surveillance, raising concerns about abuse of power by governments or corporations.",
    "member_ids": [
      "En_a423105c"
    ],
    "members": [
      {
        "id": "En_a423105c",
        "entity_name": "abuse of power",
        "entity_description": "Misuse of authority or power, potentially enabled by AI and surveillance tools.",
        "entity_type_hint": "CausalHint"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_bae93eec",
    "class_label": "Hiring Processes",
    "class_description": "Organizational procedures and workflows used to evaluate, screen, and select job applicants, including both human and algorithmic decision steps.",
    "class_type_hint": "Organizational Process",
    "class_group": "TBD",
    "confidence": 0.9,
    "evidence_excerpt": "Organizational procedures and workflows used to evaluate and select job applicants.",
    "member_ids": [
      "En_bc8da22f"
    ],
    "members": [
      {
        "id": "En_bc8da22f",
        "entity_name": "hiring processes",
        "entity_description": "Organizational procedures and workflows used to evaluate and select job applicants.",
        "entity_type_hint": "ProcessUnit"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_782428d3",
    "class_label": "Decision-Making Processes",
    "class_description": "Processes by which choices or judgments are made, including those supported or automated by AI, with attention to fairness and bias.",
    "class_type_hint": "Process",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "choices or judgments are made, often supported or automated by AI; fairness and equity in decision-making",
    "member_ids": [
      "En_3362253d"
    ],
    "members": [
      {
        "id": "En_3362253d",
        "entity_name": "decision-making processes",
        "entity_description": "Processes by which choices or judgments are made, often supported or automated by AI.",
        "entity_type_hint": "ProcessUnit"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_7c7ef516",
    "class_label": "AI Transparency Ethics",
    "class_description": "Ethical issues arising from the opacity of AI decision-making processes, focusing on challenges in interpreting, explaining, and justifying AI system outputs.",
    "class_type_hint": "Ethical Concern",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "ethical dilemma in AI development as systems become complex and opaque, challenging to understand decisions",
    "member_ids": [
      "En_0818b970"
    ],
    "members": [
      {
        "id": "En_0818b970",
        "entity_name": "ethical dilemma of transparency in AI",
        "entity_description": "The ethical challenge posed by AI systems whose decision-making processes are difficult to interpret or explain, raising concerns about transparency.",
        "entity_type_hint": "Concern"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_2437d804",
    "class_label": "Opaque AI Systems",
    "class_description": "AI systems whose internal decision-making processes are not readily interpretable or observable, raising challenges for transparency, accountability, and oversight.",
    "class_type_hint": "System Characteristic",
    "class_group": "TBD",
    "confidence": 0.9,
    "evidence_excerpt": "AI systems become more complex and opaque, making it challenging to understand how they arrive at their decisions.",
    "member_ids": [
      "En_b71727ac"
    ],
    "members": [
      {
        "id": "En_b71727ac",
        "entity_name": "opaque AI systems",
        "entity_description": "AI systems whose internal logic and decision processes are not easily observable or understandable, making their behavior difficult to interpret.",
        "entity_type_hint": "SystemCharacteristic"
      }
    ],
    "remarks": []
  },
  {
    "candidate_id": "ClsC_5d345f2e",
    "class_label": "AI Technology Harms",
    "class_description": "Negative consequences, risks, and adverse impacts that can result from the development, deployment, or use of artificial intelligence technologies.",
    "class_type_hint": "Risk Category",
    "class_group": "TBD",
    "confidence": 0.86,
    "evidence_excerpt": "negative consequences and risks that may arise from the development and deployment of AI",
    "member_ids": [
      "En_1a97574a"
    ],
    "members": [
      {
        "id": "En_1a97574a",
        "entity_name": "harms from AI technologies",
        "entity_description": "Negative consequences and risks that may arise from the development and deployment of AI.",
        "entity_type_hint": "FailureEvent"
      }
    ],
    "remarks": []
  }
]

========================
OUTPUT
========================

Return ONLY the JSON array of ordered function calls.
Return [] only if you are highly confident (> very strong evidence) that no change is needed.
If any ambiguous or conflicting evidence exists, return a concrete ordered action list
(with justifications and, optionally, confidence scores).
You are a very proactive class-resolution assistant. You are not called very proactive only by using modify_class for new_class_group. You must use other functions as well to be called a proactive class-resolution assistant.

