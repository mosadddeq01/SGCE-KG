[
  {
    "function": "set_canonical_rel",
    "args": {
      "relation_ids": [
        "RelR_8057359329a5",
        "RelR_80705e40909c"
      ],
      "canonical_rel_name": "influences_fairness_outcome",
      "canonical_rel_desc": "Design and debiasing choices in AI systems causally influence fairness- or equity-related outcomes in decision-making contexts.",
      "justification": "Both relations describe how bias handling in AI systems has a causal influence on fairness- and equity-related outcomes. The subject is AI systems and the objects are ethical outcome concepts (fairness, equity), with qualifiers pointing to causal necessity. They can share a single predicate capturing influence on ethical outcomes.",
      "remark": "Name is specialized to fairness/equity outcomes because this cluster is focused on AI ethics impacts rather than generic system effects.",
      "confidence": 0.86
    }
  },
  {
    "function": "set_rel_cls",
    "args": {
      "relation_ids": [
        "RelR_8057359329a5",
        "RelR_80705e40909c"
      ],
      "rel_cls": "ethical_outcome_influence_relation",
      "justification": "These relations express how properties or configurations of AI systems influence downstream ethical outcomes (fairness, equity) in decision-making. This is a specific family of causal relations about ethical impacts, not generic technical performance.",
      "remark": null,
      "confidence": 0.86
    }
  },
  {
    "function": "set_rel_cls_group",
    "args": {
      "relation_ids": [
        "RelR_8057359329a5",
        "RelR_80705e40909c"
      ],
      "rel_cls_group": "CAUSALITY",
      "justification": "Both instances encode that addressing or handling bias in AI systems is crucial to ensuring fairness or equity, which is a clearly causal, influence-type relation rather than mere association.",
      "remark": null,
      "confidence": 0.9
    }
  }
]