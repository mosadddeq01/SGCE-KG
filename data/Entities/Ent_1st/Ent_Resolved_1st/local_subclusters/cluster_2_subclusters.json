{
  "cluster_id": 2,
  "n_entities": 17,
  "n_subclusters": 4,
  "clusters": {
    "-1": [
      {
        "id": "En_ac8428bd",
        "entity_name": "massive amounts of data",
        "entity_type_hint": "DataAsset",
        "entity_description": "Large-scale datasets collected and analyzed by AI systems."
      },
      {
        "id": "En_bc8da22f",
        "entity_name": "hiring processes",
        "entity_type_hint": "ProcessUnit",
        "entity_description": "Organizational procedures and workflows used to evaluate and select job applicants."
      },
      {
        "id": "En_3362253d",
        "entity_name": "decision-making processes",
        "entity_type_hint": "ProcessUnit",
        "entity_description": "Processes by which choices or judgments are made, often supported or automated by AI."
      }
    ],
    "0": [
      {
        "id": "En_6c6c854a",
        "entity_name": "fairness",
        "entity_type_hint": "Condition",
        "entity_description": "The quality of decisions or processes being impartial and just across affected groups."
      },
      {
        "id": "En_d9389e81",
        "entity_name": "equity",
        "entity_type_hint": "Condition",
        "entity_description": "Condition where outcomes and opportunities are adjusted to account for structural disadvantages."
      }
    ],
    "1": [
      {
        "id": "En_5312d9e5",
        "entity_name": "bias",
        "entity_type_hint": "Concern",
        "entity_description": "Unfair or skewed behavior in AI systems that can disadvantage certain groups or outcomes."
      },
      {
        "id": "En_6fb3b228",
        "entity_name": "issue of bias",
        "entity_type_hint": "DamageMechanism",
        "entity_description": "Problem arising when AI systems reflect or amplify unfair prejudices in data."
      },
      {
        "id": "En_233d0bd9",
        "entity_name": "training data",
        "entity_type_hint": "DataAsset",
        "entity_description": "Data used to train AI systems, determining their performance and behavior."
      },
      {
        "id": "En_9bc351d3",
        "entity_name": "biased data",
        "entity_type_hint": "DataAsset",
        "entity_description": "Training data containing systematic prejudice or skew, leading to unfair AI behavior."
      },
      {
        "id": "En_34e84e77",
        "entity_name": "incomplete data",
        "entity_type_hint": "DataAsset",
        "entity_description": "Training data that lacks sufficient or representative information about the target population or domain."
      },
      {
        "id": "En_93b27f7a",
        "entity_name": "discriminatory outcomes",
        "entity_type_hint": "FailureEvent",
        "entity_description": "Unfair or unequal results produced by AI systems against certain individuals or groups."
      },
      {
        "id": "En_981f0165",
        "entity_name": "biased algorithms",
        "entity_type_hint": "DamageMechanism",
        "entity_description": "Algorithms whose design or training data leads to systematically unfair or discriminatory outcomes."
      },
      {
        "id": "En_5ae6b36d",
        "entity_name": "bias in AI systems",
        "entity_type_hint": "DamageMechanism",
        "entity_description": "Systematic and unfair skew in AI system behavior arising from data, design, or deployment."
      },
      {
        "id": "En_e950458e",
        "entity_name": "bias",
        "entity_type_hint": "Concept",
        "entity_description": "Unfair or discriminatory tendencies in AI systems arising from data or design choices."
      }
    ],
    "2": [
      {
        "id": "En_e24497ac",
        "entity_name": "discrimination",
        "entity_type_hint": "FailureEvent",
        "entity_description": "Unjust or prejudicial treatment of individuals or groups based on protected characteristics."
      },
      {
        "id": "En_aefbfcea",
        "entity_name": "race",
        "entity_type_hint": "Attribute",
        "entity_description": "A protected demographic characteristic often associated with discriminatory treatment in decisions."
      },
      {
        "id": "En_341fc99b",
        "entity_name": "gender",
        "entity_type_hint": "Attribute",
        "entity_description": "A protected demographic characteristic frequently implicated in biased or unequal treatment."
      }
    ]
  }
}